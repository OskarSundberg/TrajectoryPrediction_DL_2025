# Semantic Aware Environment Spatial-Temporal Graph Transformer
## A Single-Agent Multi-Class Trajectory Prediction Framework

by
Samuel Joseph Mcmurray

> This project was written in python utilizing docker to create a reproducable environment, 
included is a requirements.txt containing the versions used to produce the results. The 
requirements.txt was produced from the Dockerfile and would need to be run with it if the later
versions fail to run. 



This paper has been submitted for publication in *IEEE Intelligent Transportation Systems* with revisions and changes from this Thesis.
This work looks at the effects of incorporating environmental infrastructure data into Transformer models for Multi-Class Trajectory Prediction. How
these effects influence predictions in agents interactions with other agents and how agents interact with the static objects such as trees, signs, poles. 


![](manuscript/figures/hawaii-trend.png)

*Caption for the example figure with the main results.*


## Abstract

> Trajectory Prediction (TP) plays a pivotal role across various domains, transforming navigation
and interaction within complex environments. This study introduces the Semantic Aware Environ-
mental Spatial-Temporal Graph Transformer (SAE-STAR) model, designed for multi-class TP in dy-
namic urban settings. By leveraging deep learning and environmental infrastructure data, the model
forecasts the movements of pedestrians, bicyclists, and diverse vehicle types. Research questions ex-
plore enhancing prediction accuracy through infrastructure data, optimization of multi-class models,
and forecasting agent-infrastructure interactions. Integrating graph-based and deep learning techniques
aims to overcome existing TP model limitations, contributing to more accurate and reliable prediction
systems. Empirical studies and real-world experiments provide insights into TP capabilities, limita-
tions, and potential impacts on intelligent systems and decision-making processes. The study identifies
improvements in prediction accuracy with environmental data integration, notably demonstrating the
superior performance of the SAE-STAR model on the ValhallavÃ¤gen dataset compared to Semantic
Aware Spatial Temporal Graph Transformer (SA-STAR). Challenges include class imbalance effects,
complexities in static feature incorporation, and hyperparameter tuning difficulties. Quantitative analy-
sis shows an effective prediction of linear trajectories but challenges in complex scenarios corroborated
qualitatively. Future work entails refining model architectures, extensive hyperparameter optimization,
and enhancing data collection methodologies to improve TP model robustness in urban environments.


## Software implementation

> Briefly describe the software that was written to produce the results of this
> paper.

All source code used to generate the results and figures in the paper are in
the `code` folder.
The calculations and figure generation are all run inside
[Jupyter notebooks](http://jupyter.org/).
The data used in this study are privately owned and maintained by Viscando AB and is not available for the replication and use.
Results generated by the code are saved in `Results`.


## Getting the code

You can download a copy of all the files in this repository by cloning the
[git](https://git-scm.com/) repository:

    git clone https://github.com/pinga-lab/PAPER-REPO.git

or [download a zip archive](https://github.com/pinga-lab/PAPER-REPO/archive/master.zip).

A copy of the repository is also archived at *insert DOI here*


## Dependencies

You'll need a working Python environment to run the code.

### Anaconda
To set up your environment in anaconda is through the
[Anaconda Python distribution](https://www.anaconda.com/download/) which
provides the `conda` package manager.

Anaconda can be installed in your user directory and does not interfere with
the system Python installation.
The required dependencies are specified in the file `environment.yml`.

We use `conda` virtual environments to manage the project dependencies in
isolation.
Thus, you can install our dependencies without causing conflicts with your
setup (even with different Python versions).

Run the following command in the code repository folder (where `environment.yaml`
is located) to create a separate environment and install all required
dependencies in it:

    conda env create -f environment.yaml
Before running any code you must activate the conda environment:

    conda activate thesis

This will enable the environment for your current terminal session.
Any subsequent commands will use software that is installed in the environment.


### pip
The virtual environment can be installed using pip if you have not installed a virtual
environment before you will need to install the package from pip:

    pip install virtualenv

Windows:

    python -m venv venv_name
In CMD to activate the venv use:

    venv_name\Scripts\activate.bat
Powershell to activate the venv use:

venv\Scripts\Activate.ps1

In linux or Mac: 

    virtualenv venv_name
    source venv_name/bin/activate

This will enable the environment for your current terminal session.
Any subsequent commands will use software that is installed in the environment.
To install the python packages for the experiment you will need to be in the code 
directory where :

    pip install -r requirements.txt

### Docker
To set up your environment in anaconda is through the
[Get started with Docker](https://www.docker.com/get-started/) which
provides the `Docker` download links and documentation.

Using Docker offers numerous benefits by enabling consistent and efficient application deployment. 
It packages applications and their dependencies into lightweight, portable containers, ensuring 
they run reliably across different environments, from development to production. 
Docker simplifies collaboration by providing a standardized environment, reducing 
"it works on my machine" issues. It enhances scalability by allowing rapid scaling of services 
through container orchestration tools like Kubernetes. Additionally, Docker improves resource 
efficiency by sharing the host OS kernel, enabling faster start-up times and reduced overhead 
compared to traditional virtual machines. Its ease of integration with CI/CD pipelines 
accelerates development workflows, fostering agile software delivery.

The requirements.txt file is a dependency for the implementation of the environment for the code 
all that is need to run the docker environment is to have it in the folder docker will do the rest.
To execute the docker container:
    
    docker compose up -d

This will build the image and start the container the download of the image takes some time with 
many packages to download and install but it is extremely easy. Although 1 problem that I encountered 
is a problem with opencv to that follow these commands:

    docker exec -it ai-gpu-container bash 
    pip uninstall $(pip list --format=freeze | grep opencv)
    rm -rf /usr/local/lib/python3.10/dist-packages/cv2/
    pip install opencv-python-headless

The three commands uninstalling the opencv package can also be executed in docker desktop by going to the 
container and going the exec tab.


## Reproducing the results
To run the experiment in full you can execute the `main.py` file to execute the 
code in sequentual order this takes a lot of time and is resource intensive and requires
the Viscando AB data although the experiment could be modified based to replicate with 
another dataset.

Another way of exploring the code results is to execute the Jupyter notebooks
individually.
To do this, you must first start the notebook server by going into the
repository top level and running:

    jupyter notebook

If the method used is `Docker` the jupyter notebook is running and all you need to 
do is to go to [Hosted Jupyter Notebook](http://localhost:8888)

This will start the server and open your default web browser to the Jupyter
interface. In the page, go into the `notebooks` folder and select the
notebook that you wish to view/run.

The notebook is divided into cells (some have text while other have code).
Each cell can be executed using `Shift + Enter`.
Executing text cells does nothing and executing code cells runs the code
and produces it's output.
To execute the whole notebook, run all cells in order.


## License

All source code is made available under a BSD 3-clause license. You can freely
use and modify the code, without warranty, so long as you provide attribution
to the authors. See `LICENSE.md` for the full license text.

The manuscript text is not open source. The authors reserve the rights to the
article content, which is currently submitted for publication in the
JOURNAL NAME.





